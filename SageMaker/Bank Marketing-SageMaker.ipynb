{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b61cfb",
   "metadata": {},
   "source": [
    "# defines the environment variable to prepare the data, train the ML model, and deploy the ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b323331e",
   "metadata": {},
   "source": [
    "### Import the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eebfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image, display\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640472ef",
   "metadata": {},
   "source": [
    "### Define IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc73221",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "# set the region of the instance\n",
    "my_region = boto3.session.Session().region_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634dd820",
   "metadata": {},
   "source": [
    "### Define the ML algorithm XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1956d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", my_region, \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6aa60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SageMaker Instance region is: us-west-2 .\n",
      "And will use the 433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "print(\"The SageMaker Instance region is: \" + my_region + \" .\\nAnd will use the \" + xgboost_container + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbbbec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'alaa-sedeeq'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "    \n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf3181",
   "metadata": {},
   "source": [
    "### Download the data to my SageMaker instance and load the data into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfcef3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv', index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe6db7",
   "metadata": {},
   "source": [
    "### Shuffle and split the data into training data and test data. \n",
    "- The training data (70% of customers) is used during the model training loop.\n",
    "- The test data (remaining 30% of customers) is used to evaluate the performance of the model and measure how well the trained model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602556b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=0), [int(0.7 * len(model_data))])\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c08903",
   "metadata": {},
   "source": [
    "## Train the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b3b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformats the header and first column of the training data and then loads the data from the S3 bucket. \n",
    "# This step is required to use the Amazon SageMaker pre-built XGBoost algorithm.\n",
    "pd.concat(\n",
    "    [\n",
    "        train_data['y_yes'], \n",
    "        train_data.drop(['y_no', 'y_yes'], axis=1)\n",
    "    ], \n",
    "    axis=1).to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aeaa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Amazon SageMaker session, create an instance of the XGBoost model (an estimator)\n",
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    xgboost_container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket_name, prefix),\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "# Define the modelâ€™s hyperparameters\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    silent=0,\n",
    "    objective='binary:logistic',\n",
    "    num_round=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a00dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-24 11:26:16 Starting - Starting the training job...ProfilerReport-1661340376: InProgress\n",
      "...\n",
      "2022-08-24 11:27:00 Starting - Preparing the instances for training......\n",
      "2022-08-24 11:28:00 Downloading - Downloading input data......\n",
      "2022-08-24 11:29:01 Training - Downloading the training image...\n",
      "2022-08-24 11:29:45 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2022-08-24:11:29:49:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2022-08-24:11:29:49:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2022-08-24:11:29:49:INFO] File size need to be processed in the node: 3.38mb. Available memory size in the node: 8824.04mb\u001b[0m\n",
      "\u001b[34m[2022-08-24:11:29:49:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[11:29:49] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[11:29:49] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100482\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099858\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099754\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.099095\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.098991\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099303\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.099684\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.09906\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.098852\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[11:29:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098748\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.09854\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098574\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098609\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098817\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098679\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098713\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098505\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.098401\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098332\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.098332\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.09795\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.098262\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.098193\u001b[0m\n",
      "\u001b[34m[11:29:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 24 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.097985\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.097499\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097638\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097395\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097222\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097118\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097014\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.09684\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.096667\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.096736\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.096563\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.096285\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 38 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.096528\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.096459\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096355\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 34 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.096216\u001b[0m\n",
      "\u001b[34m[11:29:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096077\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.0958\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 34 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.095765\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.095904\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.095834\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.09573\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.095626\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.095696\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.095592\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.095522\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.095383\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 32 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.095661\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.095418\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 36 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[11:29:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 28 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.095314\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.095383\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.095453\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.095349\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 24 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.095245\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.095175\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 18 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.095071\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.095175\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.095002\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.095037\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.095002\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.094794\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.094759\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.094933\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.09469\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.094759\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.094482\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.094447\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.094482\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.094378\u001b[0m\n",
      "\u001b[34m[11:29:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.094343\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 28 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.094274\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.094239\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.094169\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.094169\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.094204\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 28 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.094204\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.093927\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 38 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.093927\u001b[0m\n",
      "\u001b[34m[11:29:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.093892\u001b[0m\n",
      "\n",
      "2022-08-24 11:30:17 Uploading - Uploading generated training model\n",
      "2022-08-24 11:30:17 Completed - Training job completed\n",
      "Training seconds: 137\n",
      "Billable seconds: 137\n"
     ]
    }
   ],
   "source": [
    "# trains the model using gradient optimization\n",
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ce78c",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "- Deploy the model on a server and creates a SageMaker endpoint that you can access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec915cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dfa8e",
   "metadata": {},
   "source": [
    "### Predict whether customers in the test data enrolled for the bank product or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d2ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.serializer = CSVSerializer() # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a645cc",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12cc5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Classification Rate: 89.5%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    90% (10769)    37% (167)\n",
      "Purchase        10% (1133)     63% (288) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]\n",
    "fn = cm.iloc[1,0]\n",
    "tp = cm.iloc[1,1]\n",
    "fp = cm.iloc[0,1]\n",
    "p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8caa5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to binary values\n",
    "y_true, preds = test_data.drop('y_yes', axis=1), np.where(predictions_array>0.5, 1, 0)\n",
    "# get the confusion matrix\n",
    "M = confusion_matrix(y_true, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45d9c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD4CAYAAADB0SsLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAANxklEQVR4nO3ae5iPdf7H8ednDhgmh5FjB0umA5KY7E8bKYQiSnW1sdjRsrsUtskpOWQL8atrXfXL+hFKWH67HRxCq6StjBmqcYqVtM7NjJkww5jD5/cH12S2wQ5mbvOe1+O6XNd37vt7u9/393s9576/93ec9x4RsSkk6AFEpPgocBHDFLiIYQpcxDAFLmJYWHHvIOLWQbpNX8qkJbwS9AhSRBXCcIUt1xlcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmJYWNADBG362J50btOE5MNHiXn4BQCqVa7Im5NjqVc3iu/2H6bXsFmkHz3Oo51jGNKnff62N0fXpdUvJ5O0Yx/hYaG8POIR2sREk5eXx7hXl/LO6i+5tk41po/txZXVIkk7kknsM3PZ9316QEdr25jRI1n78Rqioqrzt3eX5i+f/9abLJw/j9DQMNq0uZOhccNYtvQ95r4+K/85O3ZsZ+Hit7nxppuCGL3YOO99se4g4tZBxbuDi/SL5teRkZnFzAm98wN/fnA30o5kMnX2B8T9ugNVr6jI6GnvFtiuccO6LH65P426jgNg9G/vJTQkhPH/sxTnHFFVKpKansFbL8ay/JMtvLUknjtvu57e9/8X/Z59o6QPs0jSEl4JeoQLsiExgYoVK/LMyOH5ga+PX8fMGdN55bUZlCtXjtTUVKpXr15gu3/u2M7gJ37P8pWrgxj7kqgQhitseZm/RP904zcc/iGzwLIubZsyb0k8APOWxNP1rqY/2e6RTi1YtGJD/s99urViyuurAPDek5qeAcCNDeqwJn47AB8n7KBL25uL5TgEWsTcRuUqVQosW/yXBcQ+3p9y5coB/CRugPeXL6PzvV1KZMaSdt7AnXM3OueGO+emOef+dPqxreuYf1Oz+hUcTDkCwMGUI9SIuuInz3nonuYsWpEIQJXICADGDuzCZ/OH89aLsdQ8vc2mHfvo3q4ZAN3uvoXKkRFEValUAkchAN/t3s3GDYn0fPRhYvv0YvOmpJ88Z+WK5XS6974Apit+5wzcOTccWAg4YD2QcPrxAufciHNs1985l+icS8xJ2XIp570s3NakHpknstn6zQEAwsJCuLp2NT7/che3PzaZ+KTdTBz6AAAjX36b1i0a8vmC4bRu0ZB9h9LIyc0NcvwyJSc3lyNHjjBvwSKGPjWMp58awpkfS5OSvqJChQiio68PcMric76bbP2Axt777DMXOudeArYAkwrbyHs/A5gBl/9n8MJ8n3qU2ldW5mDKEWpfWZnkw0cLrH+4Y4v8szdAanoGGcezePfDrwD42wcb6dO9FQAHkn/g0biZAFSKKEf3ds04cuxECR2J1KpVi3btO+Cc4+amTQkJCSEtLY2oqCgAVi5fRmejZ284/yV6HlC3kOV1Tq8zadnHm+jV9ecA9Or6c5au+fGyzjnHgx1uZfHKDQW2Wb52M21iogFo2/IGvt516uxevWolnDt1/+Pp2I7MfXddSRyCnHZXu/asjz/1mu/e/S3Z2dlUq1YNgLy8PFatWkGnznYDP98ZfAiw2jn3T2DP6WXXAg2BQcU4V4mZO7EvrVtEc2XVSHaumMCE6cuZOvsD5k2OpU/3Vuw5kEbPYT9+nXJH84bsO5TO7n2pBf6f0X96h1l/7MOUuB6kpB1jwLh5ALSJiea5J+7He/jHxp0MmbioRI+vLBke9wcSE9aTnp5Gh7vb8LuBT/DAAz0Y8+woHuzWhfDwcCY8Pyn/F+6GxARq1arN1ddcE/Dkxee8X5M550KAlsBVnPr8vRdI8N7/Rx8kS+MlellXWr8mK8vO9jXZef/QxXufB+i6UqQUKvPfg4tYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzHMee+LdQf7008W7w7kkqtaKTzoEaSIKoY7V9hyncFFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDAsLeoDLyeQJz7Lu07VUrRbF7AVvA7Bm9Urm/O9r/Gv3Ll6bvYAbbmoMwLYtm/jvieMB8N7T9ze/p3XbdgAMG/xbUlOSyc3NpWmz5gx++hlCQ0ODOagy4uCBAzw7ajipKSm4kBB6PPQIj/2qN9u/3sbzz40jKyuL0NBQRj07liY3NyU7O5vnxo7m621byc3J5b77u9HvNwOCPoxLznnvi3UH+9NPFu8OLqGvvkgkIqIiE8c/kx/4d9/uwoU4Xpr0HL97Mi4/8BMnjhMeFk5oWBipKck83ush/m/pakLDwsg4doxKkZF47xk74g+0bXcPd9/TOchDK5KqlcKDHqHIkpO/JyU5mZsaNSYj4xiPPdKDl6a9ytRJL9Czd1/uaN2GT9Z+zNzXZzJzzpu8v2wJaz76iMlTX+L48eP06HYfM2e/Qd2rrg76UC5IxXDnCluuM/gZbrk1hoP79xVYVq9+g0KfW6FCRP7jkyezOPPVrRQZCUBubg45OdlQ+Gsvl1CNGjWpUaMmAJUqRVK/wXUkHzqEc46MY8cAOHbsKDVqnnoOznHieCY5OTlkZZ0gPDw8/32zRIFfhK2bk3jxj2M4dHA/o8ZNJDTsx5fz6ScH8PXWTbRsdQd33t0hwCnLnv379rJ92zaaNL2FuOGjGDjgcV6e+iJ5Po858xYA0L5DR9Z8+CEd7mrNiRMniBs2gipVqgY7eDG44Jtszrlfn2Ndf+dconMucd6cmRe6i8teoyZNmbPwHabPXsj8uTM5mZWVv27KtD/z12UfkX0ymy8S4wOcsmzJzMwgbuiTxA0fSWRkJIv/soCnho9gxeo1xA0byfgxowHYsmkToaEhrPpwLctW/J03585m7549AU9/6V3MXfTxZ1vhvZ/hvY/x3sf06vv4ReyidKhXvwEVKkTw7a6dBZaXK1+e29u05dO1HwU0WdmSnZ1N3JAn6XxfV9p1uAeApe+9Q7v2px536NiJLZuSAHh/+VJu/0VrwsPDiapenWbNmrN1y+bAZi8u5wzcOZd0ln+bgFolNONl6cD+veTm5ABw8MB+9vxrN7Xr1OV4ZiapKckA5ObkEP/ZJ1z7s/pBjlomeO8ZP2Y09Rtcx6/6/HhxWaNGTTYkrAdgffw6rq1XD4DadeqQsH4d3nuOZ2aSlPQVPzvL/ZbS7Jx30Z1zh4COQNq/rwI+897XPd8OStNd9Amjh/HlxgR+SE+nWlQUffsPpHLlKkyb+gI/pKcRGXkF111/I1Om/ZlVy5cw/41ZhIWFERISQu9+A7jjznYcTk1h1FODyM4+SW5uHs1jWjJwyLACn88vd6XxLvoXGzcQ27sn0dHX40JOnbcGDR5KZGQkUyY9T05OLuXLl2fk6DE0atyEzMwMxo4exa5vvsF7T7fuD9Intl/AR3HhznYX/XyBzwJme+//Uci6+d77x86349IUuJxSGgMv6y4o8EtBgZc+Crz0OVvg+lNVEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcMUuIhhClzEMAUuYpgCFzFMgYsYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmKYAhcxTIGLGKbARQxT4CKGKXARwxS4iGEKXMQwBS5imAIXMUyBiximwEUMU+AihilwEcOc9z7oGUot51x/7/2MoOeQ/0xZfL90Br84/YMeQIqkzL1fClzEMAUuYpgCvzhl6vOcAWXu/dJNNhHDdAYXMUyBiximwC+Ac66Tc267c26nc25E0PPIuTnnXnfOfe+c2xz0LCVNgReRcy4UeBXoDDQCfumcaxTsVHIec4BOQQ8RBAVedC2Bnd77Xd77k8BCoFvAM8k5eO/XAoeDniMICrzorgL2nPHz3tPLRC47CrzoXCHL9F2jXJYUeNHtBa454+ergf0BzSJyTgq86BKAaOdcfedcOeBR4L2AZxIplAIvIu99DjAIWAlsAxZ577cEO5Wci3NuAfA5cINzbq9zrl/QM5UU/amqiGE6g4sYpsBFDFPgIoYpcBHDFLiIYQpcxDAFLmLY/wNdfYx8ciuhRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix\n",
    "sns.heatmap(M, square=True, annot=True, cmap='Blues', fmt='d', cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fa7b43",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "- Terminate the resources used in this Notebook.\n",
    "- Terminating resources that are not actively being used reduces costs and is a best practice. \n",
    "- Not terminating your resources will result in charges to your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0046779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'ND5AJCR786JF7BTC',\n",
       "   'HostId': 'iH5K1b31DaKEGoxKvybEEluWr2rTg4CpgMwJondHM/6cumfGD1y5h4/fWXfYOzcLNw7lc+foHiE=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'iH5K1b31DaKEGoxKvybEEluWr2rTg4CpgMwJondHM/6cumfGD1y5h4/fWXfYOzcLNw7lc+foHiE=',\n",
       "    'x-amz-request-id': 'ND5AJCR786JF7BTC',\n",
       "    'date': 'Wed, 24 Aug 2022 11:47:41 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/profiler-output/system/incremental/2022082411/1661340540.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/train/train.csv'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/profiler-output/system/incremental/2022082411/1661340600.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/profiler-output/system/incremental/2022082411/1661340480.algo-1.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker/DEMO-xgboost-dm/output/xgboost-2022-08-24-11-26-16-592/rule-output/ProfilerReport-1661340376/profiler-output/profiler-reports/OverallSystemUsage.json'}]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete endpoint\n",
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "# Delete training artifacts and S3 bucket\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58ab6d",
   "metadata": {},
   "source": [
    "## The last step is to delete SageMaker Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
